# llm_chatbot_with_memory
This project is a memory-aware chatbot interface built using Gradio and powered by Hugging Face's Inference API with the mistralai/Devstral-Small-2507 model.
ğŸš€ Features
ğŸ” Conversation memory: Maintains full chat history to enable multi-turn understanding.

ğŸ§  Instruction-tuned LLM: Uses [INST] ... [/INST] prompt format for better responses.

ğŸŒ API-powered: Uses Hugging Faceâ€™s hosted model (no need to download large models locally).

ğŸ’¬ Interactive UI: Built with gr.ChatInterface() for a seamless user experience.

ğŸ”’ Secure: Requires your Hugging Face API token for authentication.

ğŸ“¦ Tech Stack
Python

Gradio

Hugging Face Hub (huggingface_hub)
