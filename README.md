# llm_chatbot_with_memory
This project is a memory-aware chatbot interface built using Gradio and powered by Hugging Face's Inference API with the mistralai/Devstral-Small-2507 model.
🚀 Features
🔁 Conversation memory: Maintains full chat history to enable multi-turn understanding.

🧠 Instruction-tuned LLM: Uses [INST] ... [/INST] prompt format for better responses.

🌐 API-powered: Uses Hugging Face’s hosted model (no need to download large models locally).

💬 Interactive UI: Built with gr.ChatInterface() for a seamless user experience.

🔒 Secure: Requires your Hugging Face API token for authentication.

📦 Tech Stack

Python

Gradio

Hugging Face Hub (huggingface_hub)

📸 Demo Screenshot

<img width="997" height="563" alt="image" src="https://github.com/user-attachments/assets/8ddd4008-8a9f-4ee0-9c0a-f4af88524c54" />


